{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T07:57:42.156044Z",
     "start_time": "2019-02-03T07:57:42.149256Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "import random\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF, CDF, Inverse-CDF Functions for Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF of normal distribution can be calculated using explicit formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.296353Z",
     "start_time": "2019-02-03T02:53:59.286650Z"
    }
   },
   "outputs": [],
   "source": [
    "def normal_pdf(x, mu, sigma=1):\n",
    "    sqrt_two_pi = math.sqrt(2*math.pi)\n",
    "    return math.exp(-(x-mu)**2/2/sigma**2/sqrt_two_pi*sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CDF of normal distribution can not be written in an elementary manner, we should use Python's math.erf.\n",
    "\n",
    "When calculate CDF, we don't need to standardize the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.311154Z",
     "start_time": "2019-02-03T02:53:59.303399Z"
    }
   },
   "outputs": [],
   "source": [
    "def normal_cdf(x, mu, sigma=1):\n",
    "    return (1 + math.erf((x-mu)/math.sqrt(2)/sigma))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.323785Z",
     "start_time": "2019-02-03T02:53:59.317758Z"
    }
   },
   "outputs": [],
   "source": [
    "normal_probability_below = normal_cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.335744Z",
     "start_time": "2019-02-03T02:53:59.330282Z"
    }
   },
   "outputs": [],
   "source": [
    "def normal_probability_above(x, mu, sigma=1):\n",
    "    return 1-normal_probability_below(x, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.350960Z",
     "start_time": "2019-02-03T02:53:59.342823Z"
    }
   },
   "outputs": [],
   "source": [
    "# it's between if it's less than hi, but not less than lo\n",
    "def normal_probability_between(lo, hi, mu=0, sigma=1):\n",
    "    return normal_probability_below(hi, mu, sigma) - normal_probability_below(lo, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.366311Z",
     "start_time": "2019-02-03T02:53:59.357659Z"
    }
   },
   "outputs": [],
   "source": [
    "# it's outside if it's not between\n",
    "def normal_probability_outside(lo, hi, mu=0, sigma=1):\n",
    "    return normal_probability_below(lo, mu, sigma) + normal_probability_above(hi, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If do the inverse calculation of the probability, we care about the how many standard deviation from X to the distribution mean, we calculate the X based on the standard normal distribution and reverse normalization to the true mu, sigma scale.\n",
    "\n",
    "Inverse of normal cdf using binary search:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.399647Z",
     "start_time": "2019-02-03T02:53:59.372023Z"
    }
   },
   "outputs": [],
   "source": [
    "def inverse_normal_cdf(p, mu=0, sigma=1, tolerance=0.00001):\n",
    "    \"\"\"find approximate inverse using binary search\"\"\"\n",
    "\n",
    "    # if not standard, compute standard and rescale\n",
    "    if mu != 0 or sigma != 1:\n",
    "        return mu + sigma * inverse_normal_cdf(p, mu=0, sigma=1, tolerance=tolerance)\n",
    "    \n",
    "    low_z, low_p = -10.0, 0            # normal_cdf(-10) is (very close to) 0\n",
    "    hi_z,  hi_p  =  10.0, 1            # normal_cdf(10)  is (very close to) 1\n",
    "    while hi_z > tolerance + low_z:\n",
    "        mid_z = low_z + (hi_z - low_z)/2     # consider the midpoint\n",
    "        mid_p = normal_cdf(mid_z, mu=0, sigma=1)      # and the cdf's value there x, mu, sigma=1\n",
    "        if mid_p < p:\n",
    "            # midpoint is still too low, search above it\n",
    "            low_z, low_p = mid_z, mid_p\n",
    "        elif mid_p > p:\n",
    "            # midpoint is still too high, search below it\n",
    "            hi_z, hi_p = mid_z, mid_p\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return mid_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.415641Z",
     "start_time": "2019-02-03T02:53:59.407339Z"
    }
   },
   "outputs": [],
   "source": [
    "def normal_upper_bound(probability, mu=0, sigma=1):\n",
    "    \"\"\"returns the z for which P(Z <= z) = probability\"\"\"\n",
    "    return inverse_normal_cdf(probability, mu, sigma, tolerance=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.430022Z",
     "start_time": "2019-02-03T02:53:59.422296Z"
    }
   },
   "outputs": [],
   "source": [
    "def normal_lower_bound(probability, mu=0, sigma=1):\n",
    "    \"\"\"returns the z for which P(Z >= z) = probability\"\"\"\n",
    "    return inverse_normal_cdf(1 - probability, mu, sigma, tolerance=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.449667Z",
     "start_time": "2019-02-03T02:53:59.436623Z"
    }
   },
   "outputs": [],
   "source": [
    "def normal_two_sided_bounds(probability, mu=0, sigma=1):\n",
    "    \"\"\"returns the symmetric (about the mean) bounds \n",
    "    that contain the specified probability\"\"\"\n",
    "    tail_probability = (1-probability) / 2\n",
    "    z_low = normal_upper_bound(tail_probability, mu, sigma)\n",
    "    z_high = normal_lower_bound(tail_probability, mu, sigma)\n",
    "    return z_low, z_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.473391Z",
     "start_time": "2019-02-03T02:53:59.457092Z"
    }
   },
   "outputs": [],
   "source": [
    "def two_sided_p_value(x, mu=0, sigma=1):\n",
    "    if x >= mu:\n",
    "        # if x is greater than the mean, the tail is above x\n",
    "        return 2 * normal_probability_above(x, mu, sigma)\n",
    "    else:\n",
    "        # if x is less than the mean, the tail is below x\n",
    "        return 2 * normal_probability_below(x, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing (Flipping a Coin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.493848Z",
     "start_time": "2019-02-03T02:53:59.481144Z"
    }
   },
   "outputs": [],
   "source": [
    "def normal_approximation_to_binomial(p,n):\n",
    "    mu = n*p\n",
    "    sigma = math.sqrt(n*p*(1-p))\n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-sided Rejection Region under Type I Error = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the hypothesis of fairness is true, then H0: p = 0.5. And suppose we flip the coin n=1000, n is large enough that X(number of heads) should be distributed approximately normal with mean = 500.0 and sigma = 15.81."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.515344Z",
     "start_time": "2019-02-03T02:53:59.507021Z"
    }
   },
   "outputs": [],
   "source": [
    "mu0,sigma0 = normal_approximation_to_binomial(0.5,1000)\n",
    "# (500.0, 15.811388300841896)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.566500Z",
     "start_time": "2019-02-03T02:53:59.523390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469.01026640487555, 530.9897335951244)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_two_sided_bounds(0.95, mu=mu0, sigma=sigma0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the two side rejection region is <469.01 or >530.99."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we set the type I error is 0.05, then if the X sits out of the bound (469.01, 530.99) then we will reject the null hypothesis that the coin is fair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Power under Type I Error = 0.05 (Two-sided Rejection Region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose Ha: p = 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.579505Z",
     "start_time": "2019-02-03T02:53:59.572837Z"
    }
   },
   "outputs": [],
   "source": [
    "mu1,sigma1 = normal_approximation_to_binomial(0.55,1000)\n",
    "#(550.0, 15.732132722552272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.612829Z",
     "start_time": "2019-02-03T02:53:59.590403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469.01026640487555, 530.9897335951244)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lo, high = normal_two_sided_bounds(0.95, mu=mu0, sigma=sigma0)\n",
    "lo, high "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type II error: when H0 is false, which means Ha is true, the probability that we fail to reject H0. This happens under Ha (p = 0.05), X sits between lo and high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.628885Z",
     "start_time": "2019-02-03T02:53:59.618389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1134519987046329"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_2_probability = normal_probability_between(lo, high, mu=mu1, sigma=sigma1)\n",
    "type_2_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:53:59.654741Z",
     "start_time": "2019-02-03T02:53:59.640615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.886548001295367"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power = 1-type_2_probability\n",
    "power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-sided Rejection Region under Type I Error = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we changed H0: p<=0.5, Ha: p>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:57:51.034950Z",
     "start_time": "2019-02-03T02:57:51.020638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526.0073585242053"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high = normal_upper_bound(0.95, mu=mu0, sigma=sigma0)\n",
    "high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the one side rejection region is >526.01, which means if the number of heads in the 1000 tosses is larger than 526.01, then we are able to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:58:38.066907Z",
     "start_time": "2019-02-03T02:58:38.061547Z"
    }
   },
   "outputs": [],
   "source": [
    "type_2_probability = normal_probability_below(high, mu=mu1, sigma=sigma1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T02:58:47.986833Z",
     "start_time": "2019-02-03T02:58:47.977257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9363794803307173"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power = 1-type_2_probability\n",
    "power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate p value (two side test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we test the hypothesis based on the rejection region. Now, we test the hypothesis based on the p-value. So what is p-value??? p-value is under null hypothesis, the probability that we observe the observation or even more extreme observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T07:46:02.663802Z",
     "start_time": "2019-02-03T07:46:02.655892Z"
    }
   },
   "outputs": [],
   "source": [
    "def two_sided_p_value(x, mu=0, sigma=1):\n",
    "    if x>=mu:\n",
    "        p = 2*normal_probability_above(x, mu, sigma)\n",
    "    else:\n",
    "        p = 2*normal_probability_below(x, mu, sigma)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's test the null hypothesis is p=0.5, and we have an observation that X = 530."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T07:46:04.729878Z",
     "start_time": "2019-02-03T07:46:04.717959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05777957112359733"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sided_p_value(530, mu=mu0, sigma=sigma0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "because 0.057779>0.05 so fail to reject H0: p=0. This result is consistent with the rejection region (469.01026640487555, 530.9897335951244)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to convince yourself is with a simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T08:12:49.916820Z",
     "start_time": "2019-02-03T08:12:49.898911Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_extreme_values(reps = 1000000):\n",
    "    extreme_value_count = 0\n",
    "    for _ in range(reps):\n",
    "        num_heads = sum(1 if random.random() < 0.5 else 0    # count # of heads\n",
    "                        for _ in range(1000))                # in 1000 flips\n",
    "        if num_heads >= 530.9897335951244 or num_heads <= 469.01026640487555:             # and count how often\n",
    "            extreme_value_count += 1                         # the # is 'extreme'\n",
    "\n",
    "    return extreme_value_count / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T08:19:15.427977Z",
     "start_time": "2019-02-03T08:12:50.955459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.053894"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_extreme_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with 1000000 times simulation, we find the probability of extreme values happens is 0.05389."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T07:53:27.008138Z",
     "start_time": "2019-02-03T07:53:26.998175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04298479507085862"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## if we saw 532 heads, p value = 0.043 < 0.05\n",
    "two_sided_p_value(532, mu=mu0, sigma=sigma0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate p value (one side test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T08:11:51.093975Z",
     "start_time": "2019-02-03T08:11:51.073985Z"
    }
   },
   "outputs": [],
   "source": [
    "upper_p_value = normal_probability_above\n",
    "lower_p_value = normal_probability_below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For out one-sided test, if we saw 525 heads we would compute as below. So we fail to reject the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T08:12:34.567951Z",
     "start_time": "2019-02-03T08:12:34.556654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056923149003329065"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_p_value(525, mu0, sigma0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we performed hypothesis testing by using rejection region, and p-value. Now we use a third method confidence interval to do the hypothesis testing.\n",
    "\n",
    "Confidence interval calculation:\n",
    "1. Given an sample, calculate the estimated mean and standard deviation.\n",
    "2. With large enough sample size n, we can use CLT to construct 95% confidence interval based on the new variable sample mean.\n",
    "3. If the confidence interval contains the hypothesis parameter, then we conclude that the hypothesis is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T23:57:07.598335Z",
     "start_time": "2019-02-04T23:57:07.576667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.525, 0.015791611697353755)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1000 tosses, 525 heads\n",
    "p_hat = 525/1000\n",
    "sigma = math.sqrt(p_hat * (1-p_hat)/1000)\n",
    "p_hat, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T00:15:33.233901Z",
     "start_time": "2019-02-05T00:15:33.218253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4940490278129096, 0.5559509721870904)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_two_sided_bounds(0.95, mu = p_hat, sigma = sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T23:52:44.787273Z",
     "start_time": "2019-02-04T23:52:44.772537Z"
    }
   },
   "source": [
    "Because mu is sitting between the region (0.4940490278129096, 0.5559509721870904), so we cannot reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T00:17:04.866911Z",
     "start_time": "2019-02-05T00:17:04.854872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.54, 0.015760710643876435)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1000 tosses, 540 heads\n",
    "p_hat = 540/1000\n",
    "sigma = math.sqrt(p_hat * (1-p_hat)/1000)\n",
    "p_hat, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T00:17:15.039711Z",
     "start_time": "2019-02-05T00:17:15.027970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5091095927295919, 0.5708904072704082)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_two_sided_bounds(0.95, mu = p_hat, sigma = sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we reject the null hypothesis. In the above case, sigma is unknown but we use p_hat to estimate the sigma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P-hacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T01:26:44.310264Z",
     "start_time": "2019-02-05T01:26:44.300027Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment():\n",
    "    return [random.random()<0.5 for _ in range(1000)] # <0.5 is True (head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T01:28:28.763415Z",
     "start_time": "2019-02-05T01:28:28.756313Z"
    }
   },
   "outputs": [],
   "source": [
    "def reject_fairness(experiment):\n",
    "    num_heads = len([flip for flip in experiment if flip])\n",
    "    return num_heads < 469 or num_heads > 531"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T01:49:33.938215Z",
     "start_time": "2019-02-05T01:49:33.355937Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "experiments = [run_experiment() for _ in range(1000)]\n",
    "num_rejections = len([experiment for experiment in experiments if reject_fairness(experiment)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T01:49:33.954463Z",
     "start_time": "2019-02-05T01:49:33.943937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rejections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Click Through Rate A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare two version of advertisements:\n",
    "\n",
    "N: # of people see the ad\n",
    "\n",
    "n: # of people click on the ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T02:02:46.476550Z",
     "start_time": "2019-02-05T02:02:46.468643Z"
    }
   },
   "outputs": [],
   "source": [
    "# approximate to normal distribution\n",
    "def estimated_parameters(N,n):\n",
    "    p = n/N\n",
    "    sigma = math.sqrt(p*(1-p)/N)\n",
    "    return p,sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If assume two normals are independent, their difference is pB-pA and standard deviation is sqrt(sigmaA^2 + sigmaB^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T02:08:31.062900Z",
     "start_time": "2019-02-05T02:08:31.046475Z"
    }
   },
   "outputs": [],
   "source": [
    "def a_b_test_statistic(N_A, n_A, N_B, n_B):\n",
    "    p_A, sigma_A = estimated_parameters(N_A, n_A)\n",
    "    p_B, sigma_B = estimated_parameters(N_B, n_B)\n",
    "    return (p_B - p_A) / math.sqrt(sigma_A ** 2 + sigma_B ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T02:09:19.259948Z",
     "start_time": "2019-02-05T02:09:19.248153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1403464899034472"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = a_b_test_statistic(1000, 200, 1000, 180)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z = -1.14034 is small enough that within -1.96~1.96, we cannot reject the null hypothesis : pA = pB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the unknown parameter is a probability (e.g. coin flipping), we often use a prior from the Beta distribution, which puts all its probability between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T06:45:17.995719Z",
     "start_time": "2019-02-05T06:45:17.978412Z"
    }
   },
   "outputs": [],
   "source": [
    "def B(alpha, beta):\n",
    "    \"\"\"a normalizing constant so that the total probability is 1\"\"\"\n",
    "    return math.gamma(alpha) * math.gamma(beta) / math.gamma(alpha + beta)\n",
    "\n",
    "def beta_pdf(x, alpha, beta):\n",
    "    if x < 0 or x > 1:          # no weight outside of [0, 1]    \n",
    "        return 0        \n",
    "    return x ** (alpha - 1) * (1 - x) ** (beta - 1) / B(alpha, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally speaking, this distribution centers its weight at:\n",
    "\n",
    "alpha/(alpha + beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Firstly, we assume the prior distribution of p is a Beta distribution with B(alpha, beta).\n",
    "* Then we flip the coin a bunch of times with h heads and t tails. With Bayes rule, the posterior distribution for p is a Beta distribution with B(alpha+h, beta+t).\n",
    "* It is no coincidence that the posterior distribution was again a Beta distribution. The number of heads is given by a Binomial distribution, and the Beta is the conjugate prior to the Binomial distribution. This means that whenever you update a Beta prior using observations from the corresponding binomial, you will get back a Beta posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
